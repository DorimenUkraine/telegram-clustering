{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'og:url': 'https://tribune.com.pk/story/2094610/4-call-self-partnered-emma-watson-single/',\n",
       " 'og:site_name': 'The Express Tribune',\n",
       " 'article:published_time': '2019-11-07T01:31:43+00:00',\n",
       " 'og:title': 'I call it self-partnered: Emma Watson on being single',\n",
       " 'og:description': 'Actor opens up on being happil\\xady on her own'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "def load_document_fields(html):\n",
    "    \"\"\"Load selected html tags to python structure\"\"\"\n",
    "    soup = bs4.BeautifulSoup(html)\n",
    "    headers = {}\n",
    "    for header in soup.html.head:\n",
    "        if header.name is not None:\n",
    "            if header.get('property'):\n",
    "                headers[header.get('property')] = header.get('content')\n",
    "    \n",
    "    related = []\n",
    "    \n",
    "    article = []\n",
    "    for tag in soup.body.article:\n",
    "        if tag.name is not None:\n",
    "            if tag.name == 'related':\n",
    "                for link in tag.children:\n",
    "                    if link.name is not None:\n",
    "                        url = link.get('href')\n",
    "                        if url:\n",
    "                            related.append(url)\n",
    "            else:\n",
    "                article.append((tag.name, tag.text))\n",
    "                        \n",
    "    return headers, article, related\n",
    "\n",
    "headers, article, related = load_document_fields(open('20191107/01/1105816787692523871.html'))\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20191101',\n",
       " '20191102',\n",
       " '20191103',\n",
       " '20191104',\n",
       " '20191105',\n",
       " '20191106',\n",
       " '20191107',\n",
       " '20191108',\n",
       " '20191109',\n",
       " '20191110',\n",
       " '20191111',\n",
       " '20191112',\n",
       " '20191113',\n",
       " '20191114',\n",
       " '20191115',\n",
       " '20191116',\n",
       " '20191117']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = !ls . | grep 2019\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 2.69 s, total: 14.1 s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "import joblib\n",
    "\n",
    "def load_dataset(pattern='2019????/??/*.html'):\n",
    "    dataset = []\n",
    "    for name in glob.glob(pattern):\n",
    "        headers, article, related = load_document_fields(open(name))\n",
    "        date, hour, file_id = name.split('/')\n",
    "        file_id = file_id.split('.')[0]\n",
    "        info = {\n",
    "            'filename': name,\n",
    "            'date': date,\n",
    "            'hour': hour,\n",
    "            'file_id': file_id,\n",
    "            'headers': headers,\n",
    "            'article': article,\n",
    "            'related': related,\n",
    "        }\n",
    "        dataset.append(info)\n",
    "    return dataset\n",
    "        \n",
    "dataset_by_date = joblib.Parallel(8)(joblib.delayed(load_dataset)(\n",
    "    '{}/??/*.html'.format(date)\n",
    ") for date in dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_indexes = []\n",
    "for dataset in dataset_by_date:\n",
    "    for article in dataset:\n",
    "        dataset_indexes.append({\n",
    "            'file_id': article['file_id'], \n",
    "            'date' : article['date'],\n",
    "            'hour': article['hour'],\n",
    "        })\n",
    "dataset = pd.DataFrame(dataset_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueness = dataset.groupby('file_id').nunique()['date']\n",
    "uniqueness = uniqueness[uniqueness > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>420227</td>\n",
       "      <td>1055835840710796728</td>\n",
       "      <td>20191116</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341402</td>\n",
       "      <td>1055835840710796728</td>\n",
       "      <td>20191114</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328628</td>\n",
       "      <td>1211837495533936170</td>\n",
       "      <td>20191114</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451914</td>\n",
       "      <td>1211837495533936170</td>\n",
       "      <td>20191117</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342291</td>\n",
       "      <td>1211837496974472896</td>\n",
       "      <td>20191114</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280059</td>\n",
       "      <td>9149753395620100820</td>\n",
       "      <td>20191113</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385832</td>\n",
       "      <td>9215450053136366527</td>\n",
       "      <td>20191115</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330474</td>\n",
       "      <td>9215450053136366527</td>\n",
       "      <td>20191114</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342500</td>\n",
       "      <td>928191164687517445</td>\n",
       "      <td>20191114</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289276</td>\n",
       "      <td>928191164687517445</td>\n",
       "      <td>20191113</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_id      date hour\n",
       "420227  1055835840710796728  20191116   05\n",
       "341402  1055835840710796728  20191114   19\n",
       "328628  1211837495533936170  20191114   21\n",
       "451914  1211837495533936170  20191117   04\n",
       "342291  1211837496974472896  20191114   19\n",
       "...                     ...       ...  ...\n",
       "280059  9149753395620100820  20191113   20\n",
       "385832  9215450053136366527  20191115   19\n",
       "330474  9215450053136366527  20191114   15\n",
       "342500   928191164687517445  20191114   02\n",
       "289276   928191164687517445  20191113   23\n",
       "\n",
       "[934 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.file_id.isin(uniqueness.index)].sort_values('file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6500716908851810728</td>\n",
       "      <td>20191101</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3780707621951097142</td>\n",
       "      <td>20191101</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2385754716373828899</td>\n",
       "      <td>20191101</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5414891177363946578</td>\n",
       "      <td>20191101</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>832941841345060939</td>\n",
       "      <td>20191101</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467478</td>\n",
       "      <td>5480941220001677487</td>\n",
       "      <td>20191117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467479</td>\n",
       "      <td>5110653854200034071</td>\n",
       "      <td>20191117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467480</td>\n",
       "      <td>7207864704140334579</td>\n",
       "      <td>20191117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467481</td>\n",
       "      <td>5575934301845427666</td>\n",
       "      <td>20191117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467482</td>\n",
       "      <td>7967730562764594048</td>\n",
       "      <td>20191117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_id      date hour\n",
       "0       6500716908851810728  20191101   07\n",
       "1       3780707621951097142  20191101   07\n",
       "2       2385754716373828899  20191101   07\n",
       "3       5414891177363946578  20191101   07\n",
       "4        832941841345060939  20191101   07\n",
       "...                     ...       ...  ...\n",
       "467478  5480941220001677487  20191117   13\n",
       "467479  5110653854200034071  20191117   13\n",
       "467480  7207864704140334579  20191117   13\n",
       "467481  5575934301845427666  20191117   13\n",
       "467482  7967730562764594048  20191117   13\n",
       "\n",
       "[467483 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_selected = []\n",
    "for dataset in dataset_by_date:\n",
    "    for article in dataset:\n",
    "        dataset_selected.append(article['headers'])\n",
    "\n",
    "dataset = pd.DataFrame(dataset_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og:url</th>\n",
       "      <th>og:site_name</th>\n",
       "      <th>article:published_time</th>\n",
       "      <th>og:title</th>\n",
       "      <th>og:description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://uaprom.info/news/171894-nbu-prognozirue...</td>\n",
       "      <td>UAprom.info</td>\n",
       "      <td>2019-11-01T07:14:06+00:00</td>\n",
       "      <td>НБУ прогнозирует сокращения транзита газа</td>\n",
       "      <td>Объем транзита природного газа через Украину м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://fedpress.ru/news/46/ecology/2356006</td>\n",
       "      <td>ФедералПресс</td>\n",
       "      <td>2019-11-01T07:14:00+00:00</td>\n",
       "      <td>«Мираторг» хочет построить свинокомплекс на ме...</td>\n",
       "      <td>Местные жители возмущены тем, что на месте бое...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://www.sigmalive.com/news/local/595172/vr...</td>\n",
       "      <td>SIGMALIVE</td>\n",
       "      <td>2019-11-01T07:10:00+00:00</td>\n",
       "      <td>Βροχές και καταιγίδες σε περιοχές της Κύπρου- ...</td>\n",
       "      <td>Χαμηλή πίεση αρχίζει να επηρεάζει την περιοχή....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://dndz.tv/article-30015.html</td>\n",
       "      <td>dndz.tv</td>\n",
       "      <td>2019-11-01T07:18:00+00:00</td>\n",
       "      <td>Волейбольная команда «ДМК» г. Каменское стала ...</td>\n",
       "      <td>В Каменском (Днепродзержинске) завершен волейб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>http://regions.ru/news/2627555/</td>\n",
       "      <td>REGIONS.RU — новости Федерации</td>\n",
       "      <td>2019-11-01T07:03:00+00:00</td>\n",
       "      <td>Александр Шерин : Московские чиновники сами пр...</td>\n",
       "      <td>Комментарий к статье Кто ближе к деньгам, тот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467478</td>\n",
       "      <td>https://www.waz.de/staedte/essen/handball-spie...</td>\n",
       "      <td>Westdeutsche Allgemeine Zeitung</td>\n",
       "      <td>2019-11-17T13:12:00+00:00</td>\n",
       "      <td>Essen: Handball-Spieler bricht beim Match zusa...</td>\n",
       "      <td>Dramatischer Zwischenfall beim Handball-Heimsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467479</td>\n",
       "      <td>https://www.sportingnews.com/us/nfl/news/nfl-p...</td>\n",
       "      <td>Sporting News</td>\n",
       "      <td>2019-11-17T13:14:00+00:00</td>\n",
       "      <td>NFL picks, predictions for Week 11: Texans get...</td>\n",
       "      <td>In our picks and predictions for Week 11 of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467480</td>\n",
       "      <td>https://nationalinterest.org/blog/buzz/75-year...</td>\n",
       "      <td>The National Interest</td>\n",
       "      <td>2019-11-17T13:00:00+00:00</td>\n",
       "      <td>75 Years Ago the USS Grayback Was Lost in the ...</td>\n",
       "      <td>Here is the story of what happened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467481</td>\n",
       "      <td>https://www.businessinsider.com.au/erling-brau...</td>\n",
       "      <td>Business Insider Australia</td>\n",
       "      <td>2019-11-17T13:08:30+00:00</td>\n",
       "      <td>A 19-year-old scores so many goals he's starti...</td>\n",
       "      <td>They say actions speak louder than words. At l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467482</td>\n",
       "      <td>https://www.theage.com.au/sport/basketball/liz...</td>\n",
       "      <td>The Age</td>\n",
       "      <td>2019-11-17T13:00:09+00:00</td>\n",
       "      <td>Liz Cambage ejected as Opals again lose to Japan</td>\n",
       "      <td>The Australian Opals have some big concerns af...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467483 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   og:url  \\\n",
       "0       http://uaprom.info/news/171894-nbu-prognozirue...   \n",
       "1             https://fedpress.ru/news/46/ecology/2356006   \n",
       "2       https://www.sigmalive.com/news/local/595172/vr...   \n",
       "3                       http://dndz.tv/article-30015.html   \n",
       "4                         http://regions.ru/news/2627555/   \n",
       "...                                                   ...   \n",
       "467478  https://www.waz.de/staedte/essen/handball-spie...   \n",
       "467479  https://www.sportingnews.com/us/nfl/news/nfl-p...   \n",
       "467480  https://nationalinterest.org/blog/buzz/75-year...   \n",
       "467481  https://www.businessinsider.com.au/erling-brau...   \n",
       "467482  https://www.theage.com.au/sport/basketball/liz...   \n",
       "\n",
       "                           og:site_name     article:published_time  \\\n",
       "0                           UAprom.info  2019-11-01T07:14:06+00:00   \n",
       "1                          ФедералПресс  2019-11-01T07:14:00+00:00   \n",
       "2                             SIGMALIVE  2019-11-01T07:10:00+00:00   \n",
       "3                               dndz.tv  2019-11-01T07:18:00+00:00   \n",
       "4        REGIONS.RU — новости Федерации  2019-11-01T07:03:00+00:00   \n",
       "...                                 ...                        ...   \n",
       "467478  Westdeutsche Allgemeine Zeitung  2019-11-17T13:12:00+00:00   \n",
       "467479                    Sporting News  2019-11-17T13:14:00+00:00   \n",
       "467480            The National Interest  2019-11-17T13:00:00+00:00   \n",
       "467481       Business Insider Australia  2019-11-17T13:08:30+00:00   \n",
       "467482                          The Age  2019-11-17T13:00:09+00:00   \n",
       "\n",
       "                                                 og:title  \\\n",
       "0               НБУ прогнозирует сокращения транзита газа   \n",
       "1       «Мираторг» хочет построить свинокомплекс на ме...   \n",
       "2       Βροχές και καταιγίδες σε περιοχές της Κύπρου- ...   \n",
       "3       Волейбольная команда «ДМК» г. Каменское стала ...   \n",
       "4       Александр Шерин : Московские чиновники сами пр...   \n",
       "...                                                   ...   \n",
       "467478  Essen: Handball-Spieler bricht beim Match zusa...   \n",
       "467479  NFL picks, predictions for Week 11: Texans get...   \n",
       "467480  75 Years Ago the USS Grayback Was Lost in the ...   \n",
       "467481  A 19-year-old scores so many goals he's starti...   \n",
       "467482   Liz Cambage ejected as Opals again lose to Japan   \n",
       "\n",
       "                                           og:description  \n",
       "0       Объем транзита природного газа через Украину м...  \n",
       "1       Местные жители возмущены тем, что на месте бое...  \n",
       "2       Χαμηλή πίεση αρχίζει να επηρεάζει την περιοχή....  \n",
       "3       В Каменском (Днепродзержинске) завершен волейб...  \n",
       "4       Комментарий к статье Кто ближе к деньгам, тот ...  \n",
       "...                                                   ...  \n",
       "467478  Dramatischer Zwischenfall beim Handball-Heimsp...  \n",
       "467479  In our picks and predictions for Week 11 of th...  \n",
       "467480                Here is the story of what happened.  \n",
       "467481  They say actions speak louder than words. At l...  \n",
       "467482  The Australian Opals have some big concerns af...  \n",
       "\n",
       "[467483 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
